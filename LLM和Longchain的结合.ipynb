{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain是什么\n",
    "\n",
    "LangChain 是用于构建大模型应用程序的开源框架，有 Python 和 JavaScript 两个不同版本的包。它由\n",
    "模块化的组件构成，可单独使用也可链式组合实现端到端应用。\n",
    "LangChain的组件包括：\n",
    "* 提示(Prompts): 使模型执行操作的方式。\n",
    "* 模型(Models)：大语言模型、对话模型，文本表示模型。目前包含多个模型的集成。\n",
    "* 索引(Indexes): 获取数据的方式，可以与模型结合使用。\n",
    "* 链(Chains): 端到端功能实现。\n",
    "* 代理(Agents): 使用模型作为推理引擎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 数据加载器\n",
    "\n",
    "用户个人数据可以以多种形式呈现：PDF 文档、视频、网页等。基于 LangChain 提供给 LLM 访问用户\n",
    "个人数据的能力，首先要加载并处理用户的多样化、非结构化个人数据。LangChain提供了各种类型的数据加载器，\n",
    "如：PDFDataLoader、TextLoader、CSVLoader、JSONLoader、UnstructuredFileLoader、UnstructuredURLLoader等。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "4\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "algorithm-visualizer.org\n",
      "算法 可视化网站，点击 play 就可以看到每一行代码的执行过程对应的动画。有 java ，  c++ ，  javascript\n",
      "等语言。 \n",
      "learngitbranching.js.org/\n",
      "一个学习 git 的可视化网站，帮助你像玩游戏一样掌握 git 的各种命令。 git 的重要性不需要多说，入门通 \n",
      "过这个网站学习可能会更加容易消化。 \n",
      " \n",
      " \n",
      " \n",
      "算法 可视化网站 \n",
      "git 可是化网站 \n",
      "https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000\n",
      "{'producer': 'Skia/PDF m100', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) ynote-desktop/8.0.0 Chrome/100.0.4896.160 Electron/18.3.5 Safari/537.36', 'creationdate': '2025-06-23T06:51:13+00:00', 'moddate': '2025-06-23T06:51:13+00:00', 'source': 'test/1.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "#pdf 加载器：\n",
    "\n",
    "#!pip install pypdf\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"test/1.pdf\")\n",
    "\n",
    "pages = loader.load()\n",
    "\n",
    "print(type(pages))  # <class 'list'>\n",
    "\n",
    "print(len(pages))\n",
    "\n",
    "\n",
    "\n",
    "#在 page 变量中，每一个元素都代表一个文档，它们的数据类型是 langchain.schema.Document\n",
    "page = pages[0]\n",
    "print(type(page))  # <class 'langchain.schema.document.Document'>\n",
    "# page 的数据结构如下：\n",
    "#      page_content ：包含该文档页面的内容\n",
    "#      metadata ：包含该文档的元数据 ,比如：{'source': 'test/1.pdf/第一回：Matplotlib初相识.pdf', 'page': 0}\n",
    "print(page.page_content)\n",
    "print(page.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['在AI的研究中，由于大模型规模非常大，模型参数很多，在大模型上跑完来验证参数好不好训练时间成本很高，所以一般会在小模型上做消融实验来验证哪些改进是有效的再去大模型上做实验。']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#短句分割\n",
    "# 导入文本分割器\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,CharacterTextSplitter\n",
    "chunk_size = 20 #设置块大小\n",
    "chunk_overlap = 10 #设置块重叠大小\n",
    "# 初始化递归字符文本分割器\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "chunk_size=chunk_size,\n",
    "chunk_overlap=chunk_overlap\n",
    ") \n",
    "#初始化字符文本分割器\n",
    "c_splitter = CharacterTextSplitter(\n",
    "chunk_size=chunk_size,\n",
    "chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "\n",
    "text = \"在AI的研究中，由于大模型规模非常大，模型参数很多，在大模型上跑完来验证参数好不好训练时间成本很高，所以一般会在小模型上做消融实验来验证哪些改进是有效的再去大模型上做实验。\"\n",
    "\n",
    "#测试文本\n",
    "r_splitter.split_text(text)\n",
    "print(\"*************\")\n",
    "c_splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['在AI的研究中，由于大模型规模非常大，模型参数很多，在大模型上跑完来验证参数好不好训练时间成',\n",
       " '�数好不好训练时间成本很高，所以一般会在小模型上做消融实验来验证哪些改进是有效的再去大模型上做',\n",
       " '有效的再去大模型上做实验。']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "\n",
    "text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 数据分片（为什么要进行文档分割）\n",
    "\n",
    "* 模型大小和内存限制：GPT 模型，特别是大型版本如 GPT-3 或 GPT-4 ，具有数十亿甚至上百亿的\n",
    "参数。为了在一次前向传播中处理这么多的参数，需要大量的计算能力和内存。但是，大多数硬件\n",
    "设备（例如 GPU 或 TPU ）有内存限制。文档分割使模型能够在这些限制内工作。\n",
    "*计算效率：处理更长的文本序列需要更多的计算资源。通过将长文档分割成更小的块，可以更高效\n",
    "地进行计算。\n",
    "* 序列长度限制：GPT 模型有一个固定的最大序列长度，例如2048个 token 。这意味着模型一次只\n",
    "能处理这么多 token 。对于超过这个长度的文档，需要进行分割才能被模型处理。\n",
    "* 更好的泛化：通过在多个文档块上进行训练，模型可以更好地学习和泛化到各种不同的文本样式和\n",
    "结构。\n",
    "* 数据增强：分割文档可以为训练数据提供更多的样本。例如，一个长文档可以被分割成多个部分，\n",
    "并分别作为单独的训练样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 数据向量化\n",
    "\n",
    "在机器学习和自然语言处理（NLP）中， Embeddings （嵌入）是一种将类别数据，如单词、句子或者整\n",
    "个文档，转化为实数向量的技术。这些实数向量可以被计算机更好地理解和处理。嵌入背后的主要想法\n",
    "是，相似或相关的对象在嵌入空间中的距离应该很近。\n",
    "\n",
    "我们可以使用词嵌入（word embeddings）来表示文本数据。在词嵌入中，每个单词被转换\n",
    "为一个向量，这个向量捕获了这个单词的语义信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 数据检索\n",
    "\n",
    "在构建检索增强生成 (RAG) 系统时，信息检索是核心环节。检索模块负责对用户查询进行分析，从知识\n",
    "库中快速定位相关文档或段落，为后续的语言生成提供信息支持。检索是指根据用户的问题去向量数据\n",
    "库中搜索与问题相关的文档内容，当我们访问和查询向量数据库时可能会运用到如下几种技术：\n",
    "* 基本语义相似度(Basic semantic similarity)\n",
    "* 最大边际相关性(Maximum marginal relevance，MMR)\n",
    "* 过滤元数据\n",
    "* LLM辅助检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    如何使用 RAG 丰富提示词？\\n\\tstep 1：在RAG向量数据库中查找原始问题的答案\\n\\tdocs = chatbot_st.query_from_doc(user_input, 3)\\n \\n\\tstep 2：使用Reranker对答案进行排序\\n    if chatbot_st.use_reranker:\\n        docs = chatbot_st.reranker.compress_documents(documents=docs, query=user_input)\\n        logging.info(\"using reranker now!!!!\")\\n\\n\\tstep 3：将相似度最高的向量对应的文本作为提示词的组成部分，拼接成新的提示词。\\n    refer = \"\\n\".join([x.page_content.replace(\"\\n\", \\'\\t\\') for x in docs])\\n    PROMPT = \"\"\"{}。\\n请根据下面的参考文档回答上述问题。\\n{}\\n\"\"\"\\n    prompt = PROMPT.format(user_input, refer)\\n    messages = [{\"role\": \"user\", \"content\": prompt}]\\n    response = client.chat.completions.create(\\n                                model=chatbot_st.llm,\\n                                messages=messages,\\n                                stream=True)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    如何使用 RAG 丰富提示词？\n",
    "\tstep 1：在RAG向量数据库中查找原始问题的答案\n",
    "\tdocs = chatbot_st.query_from_doc(user_input, 3)\n",
    " \n",
    "\tstep 2：使用Reranker对答案进行排序\n",
    "    if chatbot_st.use_reranker:\n",
    "        docs = chatbot_st.reranker.compress_documents(documents=docs, query=user_input)\n",
    "        logging.info(\"using reranker now!!!!\")\n",
    "\n",
    "\tstep 3：将相似度最高的向量对应的文本作为提示词的组成部分，拼接成新的提示词。\n",
    "    refer = \"\\n\".join([x.page_content.replace(\"\\n\", '\\t') for x in docs])\n",
    "    PROMPT = \"\"\"{}。\\n请根据下面的参考文档回答上述问题。\\n{}\\n\"\"\"\n",
    "    prompt = PROMPT.format(user_input, refer)\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "                                model=chatbot_st.llm,\n",
    "                                messages=messages,\n",
    "                                stream=True)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 向量化数据计算相似性：\n",
    "\n",
    "Faiss 提供了多种索引类型，支持不同的距离计算方式：\n",
    "\n",
    "|距离度量 |Faiss 索引类型\t|适用场景|\n",
    "|:-:|:-:|:-:|\n",
    "|L2（欧氏距离）\t|IndexFlatL2\t|图像检索、几何相似性|\n",
    "内积（IP）\t|IndexFlatIP\t|余弦相似度（需先归一化向量）|\n",
    "|余弦相似度\t|IndexFlatIP + 向量归一化\t|文本相似度（BERT 等）|\n",
    "|Jaccard\t|IndexBinaryFlat（二进制向量）\t|集合相似度|\n",
    "|Hamming\t|IndexBinaryFlat（二进制向量）\t|汉明距离（如 SimHash）|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.11.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in d:\\programdata\\miniconda3\\envs\\llm310\\lib\\site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in d:\\programdata\\miniconda3\\envs\\llm310\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Using cached faiss_cpu-1.11.0-cp310-cp310-win_amd64.whl (15.0 MB)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import time\n",
    "\n",
    "d = 64  # 向量维度\n",
    "nb = 10000  # 数据库大小\n",
    "nq = 5  # 查询数量\n",
    "np.random.seed(int(time.time()))\n",
    "xb = np.random.random((nb, d)).astype('float32')  # 数据库向量\n",
    "xq = np.random.random((nq, d)).astype('float32')  # 查询向量\n",
    "\n",
    "# 使用 L2 距离（欧氏距离）\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(xb)\n",
    "k = 4\n",
    "D, I = index.search(xq, k)\n",
    "\n",
    "print(\"L2 距离（欧氏距离）搜索结果:\")\n",
    "print(\"最近邻索引:\\n\", I)\n",
    "print(\"对应距离:\\n\", D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用内积（IP）\n",
    "index_ip = faiss.IndexFlatIP(d)\n",
    "index_ip.add(xb)\n",
    "D_ip, I_ip = index_ip.search(xq, k)\n",
    "\n",
    "print(\"\\n内积（IP）搜索结果:\")\n",
    "print(\"最近邻索引:\\n\", I_ip)\n",
    "print(\"对应内积值:\\n\", D_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "余弦相似度搜索结果（归一化后）:\n",
      "最近邻索引:\n",
      " [[9284 1602 8146 8795]\n",
      " [3505 4938 9438 1607]\n",
      " [2471  702 3017 2504]\n",
      " [4459 6301 8219 3446]\n",
      " [2436 3954 7313 2207]]\n",
      "对应余弦相似度（内积）:\n",
      " [[0.89410603 0.89023954 0.8811041  0.87891626]\n",
      " [0.87494147 0.86103094 0.8610229  0.8599931 ]\n",
      " [0.8652553  0.86274815 0.8623605  0.8580036 ]\n",
      " [0.8737376  0.86424994 0.8635894  0.862582  ]\n",
      " [0.8566244  0.837507   0.8359357  0.83164954]]\n"
     ]
    }
   ],
   "source": [
    "# 归一化向量（L2 归一化）\n",
    "xb_normalized = xb / np.linalg.norm(xb, axis=1, keepdims=True)\n",
    "xq_normalized = xq / np.linalg.norm(xq, axis=1, keepdims=True)\n",
    "\n",
    "# 使用内积（IP）计算余弦相似度\n",
    "index_ip_normalized = faiss.IndexFlatIP(d)\n",
    "index_ip_normalized.add(xb_normalized)\n",
    "D_cosine, I_cosine = index_ip_normalized.search(xq_normalized, k)\n",
    "\n",
    "print(\"\\n余弦相似度搜索结果（归一化后）:\")\n",
    "print(\"最近邻索引:\\n\", I_cosine)\n",
    "print(\"对应余弦相似度（内积）:\\n\", D_cosine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm310",
   "language": "python",
   "name": "llm310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
